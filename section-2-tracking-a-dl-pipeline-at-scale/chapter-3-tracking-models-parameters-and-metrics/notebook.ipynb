{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Tracking Models, Parameters, and Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that MLflow can support multiple scenarios through the life cycle of DL models, it is common to use MLflow's capabilities incrementally. Usually, people start with MLflow tracking since it is easy to use and can handle many scenarios for reproducibility, provenance tracking, and auditing purposes.\n",
    "\n",
    "We will then take a deep dive into how we can track a model, along with its parameters and metrics, using MLflow's tracking and registry APIs. By the end of this chapter, you should feel comfortable using MLflow's tracking and registry APIs for various reproducibility and auditing purposes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Setting up a full-fledged local MLflow tracking server**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefit of having a model registry is that we can register the model, version control the model, and prepare for model deployment into production. Therefore, this model registry will bridge the gap between offline experimentation and an online deployment production scenario. Thus, we need a full-fledged MLflow tracking server with the following stores to track the complete life cycle of a model:\n",
    "* **Backend store**: A **relational database backend is needed to support MLflow's storage of metadata** (metrics, parameters, and many others) about the experiment. This also allows the query capability of the experiment to be used. **We will use a MySQL database as a local backend store**.\n",
    "* **Artifact store**: An object store that can store arbitrary types of objects, such as serialized models, vocabulary files, figures, and many others. In a production environment, a popular choice is the AWS S3 store. We will use [**MinIO**](https://min.io/), a multi-cloud object store, as a local artifact store, which is fully compatible with the AWS S3 store API but can run on your laptop without you needing to access the cloud.\n",
    "\n",
    "To make this local setup as easy as possible, we will use the [docker-compose](https://docs.docker.com/compose/) tool with one line of command to start and stop a local full-fledged MLflow tracking server, as described in the following steps. The following steps will launch the local MLflow tracking server inside your local Docker container:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone https://github.com/PacktPublishing/Practical-Deep-Learning-at-Scale-with-MLflow/tree/main/chapter03.\n",
    "2. Change directory to the `mlflow_docker_setup` subfolder, which can be found under the chapter03 folder.\n",
    "3. Run the following command:\n",
    "```bash\n",
    "bash start_mlflow.sh\n",
    "```\n",
    "4. Go to `http://localhost/` to see the MLflow UI web page. Then, click the Models tab in the UI. Note that this tab would not work if you only had a local filesystem as the backend store for the MLflow tracking server. Hence, the MLflow UI's backend is now running on the Docker container service you just started, not a local filesystem\n",
    "5. Go to `http://localhost:9000/`, and the following screen should appear for the `MinIO` artifact store web UI. Enter `minio` for Access Key and `minio123` for Secret Key. These are defined in the `.env` file, under the `mlflow_docker_setup` folder\n",
    "\n",
    "At this point, you should have a full-fledged local MLflow tracking server running successfully! If you want to stop the server, simply type the following command:\n",
    "```bash\n",
    "bash stop_mlflow.sh\n",
    "```\n",
    "The Docker-based MLflow tracking server will stop. We are now ready to use this local MLflow server to track model provenance, parameters, and metrics."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tracking model provenance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ccdc0736e01b132d97e78ee7b194f8632625391a8773c1a4eedba6ee981c132b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
